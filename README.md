# deep-learning-challenge

The data we used here has been used multiple times throughout the class. We got it from UCBerkeley teachers.

This assignment challenged me to push my neural network above 75% accuracy, and I was unable to accomplish this.

I learned, however, that adding hidden layers helped the accuracy increase. I also learned that I shouldn't take huge steps between number of nodes in a hidden layer from layer to layer. I learned that the tanh activation function was not very good for the final layer, and I learned that the selu activation function was pretty decent in the hidden layers.

I also messed about with decreasing some of the rarer cases in the categorical columns by binning them into other categories. It was unclear if this helped the accuracy, but it did not hurt it.